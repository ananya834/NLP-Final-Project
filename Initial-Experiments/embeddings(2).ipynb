{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aa3c198",
   "metadata": {},
   "source": [
    "Get k value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41f1166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Prepare the data\n",
    "# list of text documents\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(train_data)\n",
    "\n",
    "# Determine the optimal value of k using elbow method\n",
    "\n",
    "# Determine the optimal value of k using silhouette method\n",
    "silhouette_scores = []\n",
    "for k in range(2, 11):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    silhouette_scores.append(silhouette_score(X, labels))\n",
    "plt.plot(range(2, 11), silhouette_scores)\n",
    "plt.title('Silhouette Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3daf20b",
   "metadata": {},
   "source": [
    "modify to K clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1313dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "def tsne_plot(model):\n",
    "    \"Creates and TSNE model and plots it\"\n",
    "    labels = []\n",
    "    tokens = []\n",
    "\n",
    "    for word in model.wv.key_to_index: # no longer .vocab\n",
    "        # tokens.append(model[word])\n",
    "        tokens.append(model.wv.get_vector(word))\n",
    "        labels.append(word)\n",
    "    \n",
    "    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
    "    new_values = tsne_model.fit_transform(np.array(tokens))\n",
    "\n",
    "    k = 6\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    labels = kmeans.fit_predict(new_values)\n",
    "    cmap = plt.get_cmap('Set1')  # choose a colormap\n",
    "    colors = [cmap(i) for i in np.linspace(0, 1, k)]\n",
    "    label_colors = [colors[i] for i in labels]\n",
    "\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    plt.figure(figsize=(16, 16)) \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i],y[i])\n",
    "        plt.annotate(labels[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    for i in range(k):\n",
    "        plt.scatter(new_values[labels == i, 0], new_values[labels == i, 1], color=colors[i], label='Cluster {}'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a7865f",
   "metadata": {},
   "source": [
    "GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a78232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "#https://nlp.stanford.edu/projects/glove/\n",
    "glove_input_file = 'glove.6B.100d.txt'\n",
    "word2vec_output_file = 'glove.6B.100d.txt.word2vec'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)\n",
    "\n",
    "word_to_vec_map = {}\n",
    "for word in model.vocab:\n",
    "    word_to_vec_map[word] = model[word]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "m = len(corpus) # number of sentences in the corpus\n",
    "n = model.vector_size # dimension of the GloVe vectors\n",
    "\n",
    "X = np.zeros((m,n))\n",
    "for i in range(m):\n",
    "    words = corpus[i]\n",
    "    for w in words:\n",
    "        if w in word_to_vec_map:\n",
    "            X[i] += word_to_vec_map[w]\n",
    "    X[i] /= len(words)\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "plt.scatter(X_tsne[:,0], X_tsne[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d75d3a",
   "metadata": {},
   "source": [
    "ELMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28a6d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "corpus = build_corpus(data)        \n",
    "\n",
    "# Set the paths to the ELMo model files\n",
    "options_file = \"https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
    "# https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\n",
    "weight_file = \"/Users/admin/Downloads/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
    "\n",
    "# Create an Elmo object\n",
    "elmo = Elmo(options_file, weight_file, 1, dropout=0)\n",
    "\n",
    "# Convert the sentences to character IDs\n",
    "character_ids = batch_to_ids(corpus)\n",
    "\n",
    "# Get the ELMo embeddings for the sentences\n",
    "elmo_embeddings = elmo(character_ids)\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the word embeddings for a list of words\n",
    "words = ['word1', 'word2', 'word3']\n",
    "word_embeddings = [elmo_embeddings['elmo_representations'][0][i].detach().numpy() for i in range(len(words))]\n",
    "\n",
    "# Create a TSNE object\n",
    "tsne = TSNE(n_components=2)\n",
    "\n",
    "# Fit and transform the word embeddings using t-SNE\n",
    "word_tsne = tsne.fit_transform(word_embeddings)\n",
    "\n",
    "# Plot the t-SNE results\n",
    "plt.scatter(word_tsne[:, 0], word_tsne[:, 1])\n",
    "for i, word in enumerate(words):\n",
    "    plt.annotate(word, xy=(word_tsne[i, 0], word_tsne[i, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c325efa1",
   "metadata": {},
   "source": [
    "BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bae284",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load the BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Convert the sentences to BERT input format\n",
    "input_ids = [tokenizer.encode(sentence, add_special_tokens=True) for sentence in corpus]\n",
    "input_ids = torch.tensor(input_ids)\n",
    "\n",
    "# Get the BERT embeddings for the sentences\n",
    "with torch.no_grad():\n",
    "    bert_embeddings = model(input_ids)\n",
    "    \n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the word embeddings for a list of words (Corpus)\n",
    "words = ['word1', 'word2', 'word3']\n",
    "word_embeddings = [bert_embeddings[0][i][0].detach().numpy() for i in range(len(words))]\n",
    "\n",
    "# Create a TSNE object\n",
    "tsne = TSNE(n_components=2)\n",
    "\n",
    "# Fit and transform the word embeddings using t-SNE\n",
    "word_tsne = tsne.fit_transform(word_embeddings)\n",
    "\n",
    "# Plot the t-SNE results\n",
    "plt.scatter(word_tsne[:, 0], word_tsne[:, 1])\n",
    "for i, word in enumerate(words):\n",
    "    plt.annotate(word, xy=(word_tsne[i, 0], word_tsne[i, 1]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
